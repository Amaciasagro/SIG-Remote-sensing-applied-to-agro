{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD6eXrRhQFacGG6e0JZoo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amaciasagro/SIG-Remote-sensing-applied-to-agro/blob/main/NDVI_Soil_Data_USDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248b8db0"
      },
      "source": [
        "import ee\n",
        "import geemap\n",
        "import geopandas as gpd\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Autenticar e inicializar Earth Engine (si no está autenticado)\n",
        "try:\n",
        "    ee.Initialize(project='my-project-12126-484118') # Usar tu proyecto si tienes uno, o dejar vacío\n",
        "    print(\"Earth Engine inicializado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al inicializar Earth Engine: {e}. Intentando autenticar...\")\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project='my-project-12126-484118') # Re-intentar inicializar después de autenticar\n",
        "    print(\"Earth Engine autenticado e inicializado.\")\n",
        "\n",
        "# 1. Descomprimir el archivo ZIP en el entorno de Colab\n",
        "zip_path = '/content/wss_aoi_2026-01-14_09-23-06.zip'  # <-- ASEGÚRATE DE QUE EL NOMBRE COINCIDA\n",
        "extract_path = 'datos_suelo'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"--- Archivos Shapefile encontrados en '{extract_path}' y subdirectorios ---\")\n",
        "found_shp_files = []\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for f in files:\n",
        "        if f.endswith('.shp'):\n",
        "            full_path = os.path.join(root, f)\n",
        "            found_shp_files.append(full_path)\n",
        "            print(full_path)\n",
        "\n",
        "if not found_shp_files:\n",
        "    raise FileNotFoundError(\"No se encontró ningún archivo .shp. Verifica la estructura de tu ZIP.\")\n",
        "\n",
        "print(f\"---------------------------------------\")\n",
        "\n",
        "shp_aoi_boundary = 'datos_suelo/wss_aoi_2026-01-14_09-23-06/spatial/aoi_a_aoi.shp'\n",
        "shp_soil_units = 'datos_suelo/wss_aoi_2026-01-14_09-23-06/spatial/soilmu_a_aoi.shp'\n",
        "\n",
        "os.environ['SHAPE_RESTORE_SHX'] = 'YES'\n",
        "\n",
        "aoi_boundary_gdf = gpd.read_file(shp_aoi_boundary)\n",
        "soil_units_gdf = gpd.read_file(shp_soil_units)\n",
        "\n",
        "if not aoi_boundary_gdf.empty and not soil_units_gdf.empty:\n",
        "    gdf_clipped = soil_units_gdf.clip(aoi_boundary_gdf)\n",
        "    print(f\"\\n--- GeoDataFrame RECORTADO creado --- (Filas: {gdf_clipped.shape[0]})\")\n",
        "else:\n",
        "    print(\"Advertencia: Uno de los GeoDataFrames (límite AOI o unidades de suelo) está vacío. No se realizará el recorte.\")\n",
        "    gdf_clipped = gpd.GeoDataFrame(geometry=[])\n",
        "\n",
        "features = []\n",
        "if not gdf_clipped.empty:\n",
        "    for index, row in gdf_clipped.iterrows():\n",
        "        properties = row.drop('geometry').to_dict()\n",
        "        try:\n",
        "            ee_geometry = ee.Geometry(row.geometry.__geo_interface__)\n",
        "            features.append(ee.Feature(ee_geometry, properties))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al convertir geometría para la fila {index}: {e}\")\n",
        "\n",
        "aoi_feature_collection = ee.FeatureCollection(features)\n",
        "print(f\"\\naoi_feature_collection creada con {aoi_feature_collection.size().getInfo()} features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79aeeb9d"
      },
      "source": [
        "# 1. Define Rango de Fechas\n",
        "start_date = '2025-12-01'\n",
        "end_date = '2026-01-11'\n",
        "\n",
        "# 2. Filtrar y procesar la colección Sentinel-2\n",
        "s2_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(aoi_feature_collection.geometry())\n",
        "\n",
        "# Función para enmascarar nubes - USANDO 'SCL' (Scene Classification Layer)\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('SCL')\n",
        "\n",
        "    # Crear una máscara donde los píxeles NO sean nubes oscuras, nubes medias, nubes altas o cirros.\n",
        "    # Los valores a enmascarar (consultar documentación Sentinel-2 SCL):\n",
        "    # 3 = Sombra de nubes (Cloud shadows)\n",
        "    # 8 = Nubes de probabilidad media (Cloud medium probability)\n",
        "    # 9 = Nubes de probabilidad alta (Cloud high probability)\n",
        "    # 10 = Cirros (Cirrus)\n",
        "    mask = qa.neq(3).And(qa.neq(8)).And(qa.neq(9)).And(qa.neq(10))\n",
        "\n",
        "    # Retorna la imagen enmascarada, escalada a valores de reflectancia.\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "\n",
        "s2_masked = s2_collection.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "\n",
        "# Calcular la imagen compuesta mediana después de aplicar la máscara\n",
        "median_composite = s2_masked.map(maskS2clouds).median()\n",
        "\n",
        "# 3. Calcular NDVI\n",
        "def calculate_ndvi(image):\n",
        "    nir = image.select('B8')\n",
        "    red = image.select('B4')\n",
        "    # Evitar divisiones por cero con .add(0) o .max(0.00000000001)\n",
        "    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "    return ndvi\n",
        "\n",
        "ndvi_image = calculate_ndvi(median_composite)\n",
        "\n",
        "print(\"Imagen NDVI calculada y lista para an\\u00e1lisis.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6b3e3d6"
      },
      "source": [
        "# Calcular las estadísticas de NDVI para cada polígono en aoi_feature_collection\n",
        "stats = ndvi_image.reduceRegions(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    collection=aoi_feature_collection,\n",
        "    scale=10 # Resolución de Sentinel-2 (10 metros)\n",
        ")\n",
        "\n",
        "# Convertir los resultados a un Pandas DataFrame\n",
        "df_ndvi_stats = geemap.ee_to_df(stats)\n",
        "\n",
        "# Limpiar el DataFrame: eliminar filas con NaN en 'mean' (NDVI)\n",
        "df_ndvi_stats = df_ndvi_stats.dropna(subset=['mean']).rename(columns={'mean': 'mean_ndvi'})\n",
        "\n",
        "# Calcular el NDVI promedio para cada MUKEY único\n",
        "analisis_por_mukey = df_ndvi_stats.groupby('MUKEY')['mean_ndvi'].mean().sort_values(ascending=False)\n",
        "\n",
        "# Obtener los 5 MUKEYs con mayor NDVI promedio\n",
        "top_5_mukey_ids = analisis_por_mukey.head(5).index.tolist()\n",
        "\n",
        "# Obtener los 5 MUKEYs con menor NDVI promedio, excluyendo 'W' (Water)\n",
        "# Primero, ordenar en orden ascendente para obtener los MUKEYs con menor NDVI\n",
        "analisis_por_mukey_asc = analisis_por_mukey.sort_values(ascending=True)\n",
        "\n",
        "# Mapear MUKEY a MUSYM para exclusión de 'W'\n",
        "mukey_musym_map = gdf_clipped[['MUKEY', 'MUSYM']].drop_duplicates().set_index('MUKEY')['MUSYM'].to_dict()\n",
        "\n",
        "bottom_5_mukey_ids = []\n",
        "for mukey in analisis_por_mukey_asc.index:\n",
        "    if len(bottom_5_mukey_ids) >= 5:\n",
        "        break\n",
        "    musym = mukey_musym_map.get(mukey)\n",
        "    if musym != 'W': # Excluir unidades de agua\n",
        "        bottom_5_mukey_ids.append(mukey)\n",
        "\n",
        "print(\"Estadísticas de NDVI por MUKEY calculadas.\")\n",
        "print(f\"Top 5 MUKEYs (mayor NDVI): {top_5_mukey_ids}\")\n",
        "print(f\"Bottom 5 MUKEYs (menor NDVI, excluyendo 'W'): {bottom_5_mukey_ids}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fe3a5f8"
      },
      "source": [
        "# 1. Calcular el centroide del AOI para centrar el mapa\n",
        "centroid = aoi_feature_collection.geometry().centroid().coordinates().getInfo()\n",
        "lon = centroid[0]\n",
        "lat = centroid[1]\n",
        "\n",
        "# 2. Inicializar un objeto geemap.Map() centrado en el centroide\n",
        "Map = geemap.Map(center=[lat, lon], zoom=12)\n",
        "\n",
        "# 3. Definir los parámetros de visualización para la imagen NDVI\n",
        "ndvi_vis_params = {\n",
        "    'min': -0.2,\n",
        "    'max': 0.8,\n",
        "    'palette': ['FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901', '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01', '012E01', '011D01', '011301']\n",
        "}\n",
        "\n",
        "# 4. Añadir las capas al mapa\n",
        "Map.addLayer(ndvi_image, ndvi_vis_params, 'NDVI General')\n",
        "Map.addLayer(aoi_feature_collection, {'color': 'gray', 'fillOpacity': 0.1}, 'Todas las Unidades de Suelo AOI')\n",
        "\n",
        "# Filtrar FeatureCollections para los top 5 y bottom 5 MUKEYs\n",
        "top_mukey_features = aoi_feature_collection.filter(ee.Filter.inList('MUKEY', top_5_mukey_ids))\n",
        "bottom_mukey_features = aoi_feature_collection.filter(ee.Filter.inList('MUKEY', bottom_5_mukey_ids))\n",
        "\n",
        "vis_params_green = {'color': '#014421', 'fillOpacity': 0.6}\n",
        "vis_params_red = {'color': '#D31434', 'fillOpacity': 0.6}\n",
        "\n",
        "Map.addLayer(top_mukey_features, vis_params_green, 'Top 5 NDVI MUKEYs (Verde)')\n",
        "Map.addLayer(bottom_mukey_features, vis_params_red, 'Bottom 5 NDVI MUKEYs (Rojo)')\n",
        "\n",
        "print(\"Mapas inicializado con capas NDVI y unidades de suelo.\")\n",
        "\n",
        "# 5. Configurar la interactividad del mapa al hacer clic\n",
        "def handle_map_interaction(**kwargs):\n",
        "    event_type = kwargs.get('type')\n",
        "\n",
        "    if event_type == 'click':\n",
        "        coordinates = kwargs.get('coordinates')\n",
        "        lat = None\n",
        "        lon = None\n",
        "        if coordinates and len(coordinates) == 2:\n",
        "            lon = coordinates[1]\n",
        "            lat = coordinates[0]\n",
        "\n",
        "        if lat is not None and lon is not None:\n",
        "            point = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "            # --- Extraer el valor de NDVI en el punto clickeado ---\n",
        "            ndvi_value_dict = ndvi_image.reduceRegion(\n",
        "                reducer=ee.Reducer.mean(),\n",
        "                geometry=point,\n",
        "                scale=10 # Resolución de Sentinel-2\n",
        "            ).getInfo()\n",
        "\n",
        "            ndvi_at_point = ndvi_value_dict.get('NDVI')\n",
        "            # -----------------------------------------------------\n",
        "\n",
        "            selected_feature = aoi_feature_collection.filterBounds(point).first()\n",
        "\n",
        "            print(f\"\\n--- Información del punto (Lat: {lat:.4f}, Lon: {lon:.4f}) ---\")\n",
        "            print(f\"NDVI en el píxel seleccionado: {ndvi_at_point:.4f}\")\n",
        "\n",
        "            if selected_feature:\n",
        "                mukey = selected_feature.get('MUKEY').getInfo()\n",
        "\n",
        "                if mukey:\n",
        "                    print(f\"\\n--- DETALLES DEL SUELO (MUKEY: {mukey}) ---\")\n",
        "\n",
        "                    url = \"https://sdmdataaccess.nrcs.usda.gov/Tabular/post.rest\"\n",
        "                    sql = f\"SELECT mu.muname, mu.musym, mu.farmlndcl FROM mapunit mu WHERE mu.mukey = '{mukey}'\"\n",
        "                    payload = {\"query\": sql, \"format\": \"JSON\"}\n",
        "\n",
        "                    try:\n",
        "                        response = requests.post(url, data=payload, timeout=30)\n",
        "                        data = response.json()\n",
        "\n",
        "                        if 'Table' in data and len(data['Table']) > 0:\n",
        "                            info = data['Table'][0]\n",
        "                            nombre = info[0]\n",
        "                            simbolo = info[1]\n",
        "                            clase = info[2]\n",
        "                            print(f\"Nombre de la Unidad: {nombre}\")\n",
        "                            print(f\"Símbolo: {simbolo}\")\n",
        "                            print(f\"Clase de Tierra Agrícola: {clase}\")\n",
        "                        else:\n",
        "                            print(f\"No se encontraron detalles en USDA para MUKEY: {mukey}.\")\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                        print(f\"Error al conectar con la API de USDA: {e}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Ocurrió un error inesperado al procesar la respuesta: {e}\")\n",
        "                else:\n",
        "                    print(\"No se encontró un MUKEY válido para el polígono clickeado.\")\n",
        "            else:\n",
        "                print(\"No hay un polígono de 'Unidades de Suelo AOI' en este punto.\")\n",
        "        else:\n",
        "            pass # No imprimir nada si las coordenadas no son válidas en este caso\n",
        "\n",
        "Map.on_interaction(handle_map_interaction)\n",
        "\n",
        "print(\"Interactividad activada. Haz clic en un polígono del mapa.\")\n",
        "Map # Mostrar el mapa interactivo final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11174b52"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Obtener todos los MUKEYs únicos del gdf_clipped\n",
        "unique_mukeys = gdf_clipped['MUKEY'].unique().tolist()\n",
        "\n",
        "# Convertir la lista de MUKEYs en una cadena para la consulta SQL\n",
        "mukeys_str = \"','\".join(unique_mukeys)\n",
        "\n",
        "# Construir la consulta SQL para obtener detalles de suelo de USDA\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "    mapunit.mukey AS MUKEY,\n",
        "    mapunit.muname AS NOMBRE_SUELO,\n",
        "    mapunit.musym AS SIMBOLO,\n",
        "    mapunit.farmlndcl AS CLASE_AGR\n",
        "FROM\n",
        "    mapunit\n",
        "WHERE\n",
        "    mapunit.mukey IN ('{mukeys_str}')\n",
        "\"\"\"\n",
        "\n",
        "url = \"https://sdmdataaccess.nrcs.usda.gov/Tabular/post.rest\"\n",
        "payload = {\"query\": sql, \"format\": \"JSON+COLUMNNAME\"}\n",
        "\n",
        "print(\"Consultando detalles de suelo a la API de USDA...\")\n",
        "try:\n",
        "    response = requests.post(url, data=payload, timeout=60) # Aumentar timeout si es necesario\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        res_json = response.json()\n",
        "        if 'Table' in res_json and len(res_json['Table']) > 1: # Hay que tener en cuenta la fila de encabezado\n",
        "            columns = res_json['Table'][0]\n",
        "            data = res_json['Table'][1:]\n",
        "            df_suelos = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "            # Asegurarse de que 'MUKEY' es de tipo string para consistencia\n",
        "            df_suelos['MUKEY'] = df_suelos['MUKEY'].astype(str)\n",
        "\n",
        "            print(\"✅ DataFrame 'df_suelos' creado con éxito a partir de la API de USDA.\")\n",
        "            display(df_suelos.head())\n",
        "        else:\n",
        "            print(\"Advertencia: No se encontraron datos en la respuesta de USDA o la tabla está vacía.\")\n",
        "            df_suelos = pd.DataFrame(columns=['MUKEY', 'NOMBRE_SUELO', 'SIMBOLO', 'CLASE_AGR']) # DataFrame vacío\n",
        "    else:\n",
        "        print(f\"Error al consultar la API de USDA: {response.status_code} - {response.text}\")\n",
        "        df_suelos = pd.DataFrame(columns=['MUKEY', 'NOMBRE_SUELO', 'SIMBOLO', 'CLASE_AGR']) # DataFrame vacío\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Fallo de conexión con la API de USDA: {e}\")\n",
        "    df_suelos = pd.DataFrame(columns=['MUKEY', 'NOMBRE_SUELO', 'SIMBOLO', 'CLASE_AGR']) # DataFrame vacío\n",
        "\n",
        "# Extraer el nombre de la serie de la columna 'NOMBRE_SUELO'\n",
        "df_suelos['Series_Name'] = df_suelos['NOMBRE_SUELO'].apply(lambda x: x.split(' ')[0] if isinstance(x, str) else None)\n",
        "\n",
        "# Seleccionar las columnas requeridas y eliminar duplicados para obtener una lista única\n",
        "musym_mukey_series_list = df_suelos[['MUKEY', 'SIMBOLO', 'Series_Name']].drop_duplicates().sort_values(by=['SIMBOLO', 'MUKEY'])\n",
        "\n",
        "print(\"--- Lista de MUKEY, MUSYM y Nombres de Serie --- \")\n",
        "display(musym_mukey_series_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def link_osd_suelo(nombre_serie):\n",
        "    # Limpiamos el nombre y obtenemos la inicial\n",
        "    serie = nombre_serie.strip().upper()\n",
        "    inicial = serie[0]\n",
        "\n",
        "    # URL oficial del repositorio de la USDA\n",
        "    url_osd = f\"https://soilseries.sc.egov.usda.gov/OSD_Docs/{inicial}/{serie}.html\"\n",
        "\n",
        "    # URL de la interfaz visual de SoilWeb (opcional)\n",
        "    url_soilweb = f\"https://casoilresource.lawr.ucdavis.edu/sde/?series={serie.lower()}\"\n",
        "\n",
        "    return url_osd, url_soilweb\n",
        "\n",
        "# Ejemplo // osd, web = link_osd_suelo(\"ACA VA EL NOMBRE DE LA SERIE\")\n",
        "osd, web = link_osd_suelo(\"Highbank\")\n",
        "print(f\"Documento Técnico (PDF/HTML): {osd}\")\n",
        "print(f\"Interfaz Visual SoilWeb: {web}\")"
      ],
      "metadata": {
        "id": "P3UX2FsHYvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5887d911"
      },
      "source": [
        "import altair as alt\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Asegurarse de que df_ndvi_stats y df_suelos están disponibles en el entorno\n",
        "# (se asume que las celdas de carga de datos y cálculo de NDVI ya se han ejecutado)\n",
        "\n",
        "# 1. Limpiar df_suelos para asegurar consistencia y extraer Series_Name\n",
        "# Se asume que df_suelos tiene una fila de encabezado duplicada que debe ser eliminada (iloc[1:])\n",
        "df_suelos_cleaned = df_suelos.iloc[1:].copy().reset_index(drop=True)\n",
        "# Asegurarse de que 'MUKEY' sea de tipo string para fusiones\n",
        "df_suelos_cleaned['MUKEY'] = df_suelos_cleaned['MUKEY'].astype(str)\n",
        "# Extraer el nombre principal de la serie de la columna 'NOMBRE_SUELO'\n",
        "df_suelos_cleaned['Series_Name'] = df_suelos_cleaned['NOMBRE_SUELO'].apply(lambda x: x.split(' ')[0] if isinstance(x, str) else None)\n",
        "\n",
        "# 2. Primero, agregar df_ndvi_stats por MUKEY para obtener un solo NDVI promedio por MUKEY\n",
        "df_ndvi_stats_agg_mukey = df_ndvi_stats.groupby('MUKEY', as_index=False)['mean_ndvi'].mean()\n",
        "\n",
        "# 3. Fusionar el NDVI promedio por MUKEY con la información limpia de df_suelos\n",
        "# Corregido: Usar 'SIMBOLO' en lugar de 'MUSYM' en df_suelos_cleaned\n",
        "data_at_mukey_level = pd.merge(\n",
        "    df_ndvi_stats_agg_mukey,\n",
        "    df_suelos_cleaned[['MUKEY', 'SIMBOLO', 'NOMBRE_SUELO', 'CLASE_AGR', 'Series_Name']],\n",
        "    on='MUKEY',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 4. Filtrar las unidades de suelo donde MUSYM es 'W' (agua)\n",
        "# Corregido: Usar 'SIMBOLO' en lugar de 'MUSYM'\n",
        "data_for_chart = data_at_mukey_level[data_at_mukey_level['SIMBOLO'] != 'W'].copy()\n",
        "\n",
        "# 5. Agrupar los datos por Series_Name para calcular el NDVI promedio por serie\n",
        "# También agregamos CLASE_AGR, MUKEY y MUSYM para el tooltip\n",
        "aggregated_series_data = data_for_chart.groupby('Series_Name', as_index=False).agg(\n",
        "    mean_ndvi=('mean_ndvi', 'mean'),\n",
        "    # Para tooltip, unir los valores únicos o tomar el más frecuente si hay muchos\n",
        "    clase_agr_tooltip=('CLASE_AGR', lambda x: ', '.join(x.unique()) if x.nunique() <= 3 else x.mode()[0]),\n",
        "    mukey_tooltip=('MUKEY', lambda x: ', '.join(x.unique()) if x.nunique() <= 3 else x.mode()[0]),\n",
        "    # Corregido: Usar 'SIMBOLO' en lugar de 'MUSYM'\n",
        "    musym_tooltip=('SIMBOLO', lambda x: ', '.join(x.unique()) if x.nunique() <= 3 else x.mode()[0]),\n",
        "    # Añadir NOMBRE_SUELO al agregador para que esté disponible en el tooltip\n",
        "    nombre_suelo_tooltip=('NOMBRE_SUELO', lambda x: ', '.join(x.unique()) if x.nunique() <= 3 else x.mode()[0])\n",
        ").sort_values('mean_ndvi', ascending=False)\n",
        "\n",
        "# 6. Crear el gráfico de barras vertical con Altair\n",
        "chart = alt.Chart(aggregated_series_data).mark_bar(color='steelblue').encode(\n",
        "    x=alt.X('Series_Name:N', sort='-y', axis=alt.Axis(\n",
        "        title='Nombre de Serie de Suelo',\n",
        "        labelAngle=-45 # Rotar etiquetas para mejorar la legibilidad\n",
        "    )),\n",
        "    y=alt.Y('mean_ndvi:Q', axis=alt.Axis(\n",
        "        title='NDVI Promedio',\n",
        "        titleColor='darkblue' # Color del título del eje Y\n",
        "    )),\n",
        "    tooltip=[\n",
        "        alt.Tooltip('Series_Name:N', title='Serie de Suelo'),\n",
        "        alt.Tooltip('mean_ndvi:Q', format='.3f', title='NDVI Promedio'),\n",
        "        alt.Tooltip('nombre_suelo_tooltip:N', title='Descripción de Suelo'), # Nuevo tooltip para el nombre completo\n",
        "        alt.Tooltip('clase_agr_tooltip:N', title='Clase Agrícola'),\n",
        "        alt.Tooltip('mukey_tooltip:N', title='MUKEY(s) Asociados'),\n",
        "        alt.Tooltip('musym_tooltip:N', title='MUSYM(s) Asociados')\n",
        "    ]\n",
        ").properties(\n",
        "    title='NDVI Promedio por Serie de Suelo (Excluyendo Unidades de Agua)',\n",
        "    width=800, # Ajustar ancho del gráfico\n",
        "    height=500 # Ajustar alto del gráfico\n",
        ").interactive() # Permite zoom y paneo\n",
        "\n",
        "# Mostrar el gráfico\n",
        "display(chart)\n",
        "\n",
        "print(\"Gráfico de barras vertical interactivo por Nombre de Serie de Suelo generado.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}